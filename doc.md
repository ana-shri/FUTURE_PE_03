üß† Prompt Strategy & Tone Control Documentation
1. Objective

The goal of this project was to design a chatbot persona that delivers emotionally supportive, human-like conversations using structured prompt engineering and tone control. The chatbot (Aurora) was designed to assist users with emotional check-ins, stress management, and reflective conversations.

2. Persona-Driven Prompt Design

The chatbot‚Äôs behavior is governed by a system-level prompt that defines:

Role and purpose

Emotional boundaries

Tone and communication style

Safety constraints

Core Persona Prompt
You are Aurora, an AI Mental Health Companion.
Your role is to provide emotional support in a calm, empathetic, and non-judgmental manner.
Always validate the user's emotions and encourage reflection.
Avoid diagnosing medical or mental health conditions.
Do not provide crisis intervention or professional advice.
Use short, warm, and supportive responses.


This prompt ensures consistency in:

Emotional intelligence

Response structure

User experience

3. Tone Control Strategy

Tone control was achieved through explicit behavioral constraints rather than relying on default AI responses.

Tone Characteristics
Aspect	Implementation
Empathy	Emotion validation before suggestions
Calmness	Short sentences and soft language
Safety	No medical or diagnostic advice
Support	Encouraging, non-directive responses
Clarity	Simple and easy-to-understand language

Example:

‚ÄúThat sounds really overwhelming. I‚Äôm glad you shared this with me.‚Äù

4. Conversation Flow Strategy

Aurora follows a guided conversational flow:

Acknowledge emotion

Validate experience

Ask an open-ended follow-up

Offer optional support

Avoid forced solutions

This approach prevents:

Overwhelming the user

Giving unsafe advice

Robotic interactions

5. Prompt Chaining Logic

Instead of one long response, the chatbot uses prompt chaining, where:

Each response depends on the user‚Äôs emotional context

Follow-up questions guide deeper reflection

Suggestions are offered only when appropriate

This creates:

Natural dialogue progression

Context-aware replies

Higher user trust

6. Fallback & Safety Handling

Fallback logic is used when:

User input is unclear

Questions are outside scope

Sensitive topics appear

Example fallback:

‚ÄúI want to support you, but I might not be the best source for that. Would you like to talk about how this is making you feel instead?‚Äù

This ensures ethical and safe AI behavior.

7. Tools & Implementation

Platform: Tidio (Lyro AI Agent)

Prompt Control: System-level persona instructions

Testing: Tidio Playground (Live Chat Simulation)

Documentation: GitHub & Notion

8. Key Learnings

Clear system prompts drastically improve consistency

Tone control is more important than feature complexity

Simple, empathetic language enhances user trust

No-code platforms can still support advanced prompt engineering

9. Conclusion

This project demonstrates how prompt engineering, tone control, and persona design can be combined to build an emotionally aware chatbot using no-code tools. Aurora showcases responsible AI design with a focus on user wellbeing and conversational quality.
